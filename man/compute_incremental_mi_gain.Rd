% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/node_scoring.R
\name{compute_incremental_mi_gain}
\alias{compute_incremental_mi_gain}
\title{Compute cumulative conditional mutual information gain for a candidate set}
\usage{
compute_incremental_mi_gain(
  target,
  candidates,
  conditioning_set,
  data,
  hash_table
)
}
\arguments{
\item{target}{The name of the target variable.}

\item{candidates}{A vector of variable names to be added incrementally to the conditioning set.}

\item{conditioning_set}{A character vector representing the current conditioning set (possibly empty).}

\item{data}{A data frame containing all variables (columns) and observations (rows).}

\item{hash_table}{An environment or named list used to cache mutual information computations.}
}
\value{
A list with:
\describe{
\item{score}{The total(conditional) mutual information gain from adding all candidates.}
\item{hash_table}{The updated cache of mutual information values.}
}
}
\description{
For a given target variable, this function evaluates the cumulative gain in conditional
mutual information (MI) when successively adding variables from \code{candidates} to an initial
conditioning set. Each MI computation is cached using a hash table to improve efficiency.
}
\details{
This function supports the greedy selection of local conditioning sets during
Step 1 of the MIIC_search&score algorithm for causal graph discovery.
}
\references{
Lagrange, N. and Isambert, H. (2025).
An efficient search-and-score algorithm for ancestral graphs using multivariate information scores.
In \emph{Proceedings of the 42nd International Conference on Machine Learning (ICML 2025)}.
}
